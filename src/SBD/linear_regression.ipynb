{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L03.1 Linear Regression Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3],[4, 5, 6], [7, 8, 9]])\n",
    "print(x.type())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape)\n",
    "print(x.ndimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "y = torch.FloatTensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[1, 2], [3, 4]]])\n",
    "print(y.shape)\n",
    "print(y.ndimension()) # == len(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]],\n",
      "\n",
      "        [[1., 2.],\n",
      "         [3., 4.]]])\n",
      "origianl shape:  torch.Size([3, 2, 2])\n",
      "tensor([[[[1., 2.],\n",
      "          [3., 4.]],\n",
      "\n",
      "         [[5., 6.],\n",
      "          [7., 8.]],\n",
      "\n",
      "         [[1., 2.],\n",
      "          [3., 4.]]]])\n",
      "unsqueeze(0):  torch.Size([1, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(\"origianl shape: \", y.shape)\n",
    "\n",
    "y0 =y.unsqueeze(0)\n",
    "print(y0)\n",
    "print(\"unsqueeze(0): \", y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 2.],\n",
      "          [3., 4.]],\n",
      "\n",
      "         [[5., 6.],\n",
      "          [7., 8.]],\n",
      "\n",
      "         [[1., 2.],\n",
      "          [3., 4.]]]])\n",
      "tensor([[[[1., 2.],\n",
      "          [3., 4.]]],\n",
      "\n",
      "\n",
      "        [[[5., 6.],\n",
      "          [7., 8.]]],\n",
      "\n",
      "\n",
      "        [[[1., 2.],\n",
      "          [3., 4.]]]])\n",
      "tensor([[[[1., 2.]],\n",
      "\n",
      "         [[3., 4.]]],\n",
      "\n",
      "\n",
      "        [[[5., 6.]],\n",
      "\n",
      "         [[7., 8.]]],\n",
      "\n",
      "\n",
      "        [[[1., 2.]],\n",
      "\n",
      "         [[3., 4.]]]])\n",
      "tensor([[[[1.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [4.]]],\n",
      "\n",
      "\n",
      "        [[[5.],\n",
      "          [6.]],\n",
      "\n",
      "         [[7.],\n",
      "          [8.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [2.]],\n",
      "\n",
      "         [[3.],\n",
      "          [4.]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[1, 2], [3, 4]]])\n",
    "\n",
    "x0 = x.unsqueeze(0) # [3, 2, 2] --> [1, 3, 2, 2]\n",
    "x1 = x.unsqueeze(1) # [3, 2, 2] --> [3, 1, 2, 2]\n",
    "x2 = x.unsqueeze(2) # [3, 2, 2] --> [3, 2, 1, 2]\n",
    "x3 = x.unsqueeze(3) # [3, 2, 2] --> [3, 2, 2, 1]\n",
    "\n",
    "print(x0)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "xt = x.unsqueeze(0).unsqueeze(1).unsqueeze(0).unsqueeze(5) # 1, 1, 1, 3, 2, 1, 2\n",
    "print(xt.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0155],\n",
      "        [5.5607],\n",
      "        [9.1829]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4], [5, 6]]) # 3 x 2\n",
    "w = torch.rand(1, 2, dtype=torch.float)  # 2 x 1\n",
    "b = torch.rand(3, 1, dtype=torch.float)\n",
    "\n",
    "print(x @ w.T + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(4.0, requires_grad=True)\n",
    "a = w*3\n",
    "l = a**2\n",
    "l.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6212],\n",
      "        [-1.0627]]) tensor([[-0.5556]])\n",
      "Epoch 0: Cost = 150.5323028564453, W = [2.0165417194366455, -0.2400374412536621], b = -0.4158027768135071\n",
      "Epoch 100: Cost = 0.8111913800239563, W = [1.2574418783187866, 2.984672784805298], b = -2.1462292671203613\n",
      "Epoch 200: Cost = 0.3320358395576477, W = [1.302392840385437, 3.1093032360076904], b = -2.7852845191955566\n",
      "Epoch 300: Cost = 0.16955049335956573, W = [1.4811729192733765, 3.0919857025146484], b = -3.1421332359313965\n",
      "Epoch 400: Cost = 0.08712118119001389, W = [1.6259409189224243, 3.0674870014190674], b = -3.3864777088165283\n",
      "Epoch 500: Cost = 0.04477297514677048, W = [1.7316036224365234, 3.0485548973083496], b = -3.5603432655334473\n",
      "Epoch 600: Cost = 0.023009853437542915, W = [1.8075642585754395, 3.034827947616577], b = -3.6848363876342773\n",
      "Epoch 700: Cost = 0.011825117282569408, W = [1.8620431423187256, 3.024970293045044], b = -3.7740676403045654\n",
      "Epoch 800: Cost = 0.006077134981751442, W = [1.9011012315750122, 3.0179007053375244], b = -3.838033676147461\n",
      "Epoch 900: Cost = 0.003123207949101925, W = [1.9291009902954102, 3.0128324031829834], b = -3.8838882446289062\n",
      "Epoch 1000: Cost = 0.0016050856793299317, W = [1.9491734504699707, 3.009199380874634], b = -3.9167613983154297\n",
      "Epoch 1100: Cost = 0.0008248984813690186, W = [1.963563084602356, 3.0065951347351074], b = -3.9403274059295654\n",
      "Epoch 1200: Cost = 0.00042394758202135563, W = [1.973879098892212, 3.004727840423584], b = -3.957221269607544\n",
      "Epoch 1300: Cost = 0.0002178865543100983, W = [1.981274127960205, 3.003389358520508], b = -3.969331979751587\n",
      "Epoch 1400: Cost = 0.00011197351705050096, W = [1.9865752458572388, 3.0024302005767822], b = -3.9780149459838867\n",
      "Epoch 1500: Cost = 5.7547487813280895e-05, W = [1.9903757572174072, 3.001742124557495], b = -3.984238624572754\n",
      "Epoch 1600: Cost = 2.9573082429124042e-05, W = [1.993100643157959, 3.001248836517334], b = -3.988701343536377\n",
      "Epoch 1700: Cost = 1.5198545952443965e-05, W = [1.9950536489486694, 3.0008955001831055], b = -3.9918999671936035\n",
      "Epoch 1800: Cost = 7.80975642555859e-06, W = [1.9964542388916016, 3.0006418228149414], b = -3.9941935539245605\n",
      "Epoch 1900: Cost = 4.013045781903202e-06, W = [1.9974581003189087, 3.000460147857666], b = -3.995837688446045\n",
      "Epoch 2000: Cost = 2.0632558062061435e-06, W = [1.9981778860092163, 3.0003297328948975], b = -3.9970157146453857\n",
      "Epoch 2100: Cost = 1.0604902627164847e-06, W = [1.998693585395813, 3.0002362728118896], b = -3.9978604316711426\n",
      "Epoch 2200: Cost = 5.450960998132359e-07, W = [1.99906325340271, 3.000169515609741], b = -3.9984662532806396\n",
      "Epoch 2300: Cost = 2.802397034429305e-07, W = [1.99932861328125, 3.0001213550567627], b = -3.9989001750946045\n",
      "Epoch 2400: Cost = 1.4440779239066615e-07, W = [1.9995180368423462, 3.0000874996185303], b = -3.999211072921753\n",
      "Epoch 2500: Cost = 7.42115062735138e-08, W = [1.9996541738510132, 3.0000624656677246], b = -3.999433755874634\n",
      "Epoch 2600: Cost = 3.8266254165364444e-08, W = [1.9997522830963135, 3.000044584274292], b = -3.99959397315979\n",
      "Epoch 2700: Cost = 1.9808942042232047e-08, W = [1.9998220205307007, 3.0000321865081787], b = -3.9997076988220215\n",
      "Epoch 2800: Cost = 1.0268945693781006e-08, W = [1.9998716115951538, 3.000023126602173], b = -3.999789237976074\n",
      "Epoch 2900: Cost = 5.425704330264125e-09, W = [1.9999067783355713, 3.000016689300537], b = -3.9998462200164795\n",
      "Epoch 3000: Cost = 2.796949116756764e-09, W = [1.9999314546585083, 3.0000133514404297], b = -3.9998910427093506\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train = torch.FloatTensor([[1, 2], [3, 2], [3, 7], [1, 1], [1, 0]])\n",
    "y_train = torch.FloatTensor([[4], [8], [23], [1], [-2]])\n",
    "\n",
    "W = torch.randn(2, 1)\n",
    "b = torch.randn(1, 1)\n",
    "print(W, b)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "for epoch in range(3001):\n",
    "    W.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "\n",
    "    h = x_train @ W + b\n",
    "    cost = ((y_train - h)**2).mean()\n",
    "\n",
    "    cost.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        W = W - lr * W.grad\n",
    "        b = b - lr * b.grad\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Cost = {cost.item()}, W = {W.squeeze().tolist()}, b = {b.squeeze().item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35.9999],\n",
      "        [21.0001],\n",
      "        [32.0000]])\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.FloatTensor([[5, 10], [2, 7], [3, 10]])\n",
    "\n",
    "y_test = x_test @ W + b\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3.]] [-4.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = [[1, 2], [3, 2], [3 ,7], [1, 1], [1, 0]]\n",
    "y = [[4], [8], [23], [1], [-2]]\n",
    "\n",
    "lr = LinearRegression() # 모델 생성\n",
    "lr.fit(x, y) # 학습 (피팅)\n",
    "\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36.]\n",
      " [21.]\n",
      " [25.]]\n"
     ]
    }
   ],
   "source": [
    "x_test = [[5, 10], [2, 7], [10, 3]]\n",
    "y_test = lr.predict(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L04.1 Logistic Regression Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train = torch.FloatTensor([[1], [2], [3], [4], [5], [2.5], [3.5], [0], [3.1], [2.7], [2.8], [2.9]])\n",
    "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cost = 1.684381365776062, W = 0.29679399728775024, b = -0.5576716661453247\n",
      "Epoch 100: Cost = 0.42231765389442444, W = -1.4192560911178589, b = 4.308471202850342\n",
      "Epoch 200: Cost = 0.3993443548679352, W = -1.8807520866394043, b = 5.720011234283447\n",
      "Epoch 300: Cost = 0.39109599590301514, W = -2.1624886989593506, b = 6.573801040649414\n",
      "Epoch 400: Cost = 0.3871525228023529, W = -2.3587496280670166, b = 7.165768623352051\n",
      "Epoch 500: Cost = 0.3850063979625702, W = -2.504127025604248, b = 7.6030073165893555\n",
      "Epoch 600: Cost = 0.3837484121322632, W = -2.615719795227051, b = 7.937989711761475\n",
      "Epoch 700: Cost = 0.38297465443611145, W = -2.7033843994140625, b = 8.200782775878906\n",
      "Epoch 800: Cost = 0.3824829161167145, W = -2.773369312286377, b = 8.410362243652344\n",
      "Epoch 900: Cost = 0.3821626603603363, W = -2.8299002647399902, b = 8.579521179199219\n",
      "Epoch 1000: Cost = 0.3819502890110016, W = -2.875969886779785, b = 8.717293739318848\n",
      "Epoch 1100: Cost = 0.38180744647979736, W = -2.9137661457061768, b = 8.830268859863281\n",
      "Epoch 1200: Cost = 0.38171032071113586, W = -2.9449450969696045, b = 8.923429489135742\n",
      "Epoch 1300: Cost = 0.38164374232292175, W = -2.9707694053649902, b = 9.000566482543945\n",
      "Epoch 1400: Cost = 0.38159796595573425, W = -2.9922332763671875, b = 9.064661979675293\n",
      "Epoch 1500: Cost = 0.38156595826148987, W = -3.010125160217285, b = 9.118081092834473\n",
      "Epoch 1600: Cost = 0.38154375553131104, W = -3.025071382522583, b = 9.162696838378906\n",
      "Epoch 1700: Cost = 0.3815281093120575, W = -3.0375802516937256, b = 9.200030326843262\n",
      "Epoch 1800: Cost = 0.3815171718597412, W = -3.048064708709717, b = 9.231319427490234\n",
      "Epoch 1900: Cost = 0.3815094232559204, W = -3.056863784790039, b = 9.257575988769531\n",
      "Epoch 2000: Cost = 0.381504088640213, W = -3.064255714416504, b = 9.279632568359375\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "w = torch.randn(1, 1)\n",
    "b = torch.randn(1, 1)\n",
    "\n",
    "lr = 1.0\n",
    "\n",
    "for epoch in range(2001):\n",
    "    w.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "\n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "    #h = 1 / (1 + math.e ** (-(x_train @ w + b)))\n",
    "\n",
    "    cost = torch.mean(-y_train * torch.log(h) - (1-y_train) * torch.log(1-h))  # BCE\n",
    "\n",
    "    cost.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Cost = {cost.item()}, W = {w.squeeze().tolist()}, b = {b.squeeze().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cost = 0.8460483551025391, W = -0.4619423747062683, b = -0.13109292089939117\n",
      "Epoch 100: Cost = 0.42047008872032166, W = -1.447409987449646, b = 4.3950090408325195\n",
      "Epoch 200: Cost = 0.3987967073917389, W = -1.896276593208313, b = 5.7671966552734375\n",
      "Epoch 300: Cost = 0.3908538520336151, W = -2.1728758811950684, b = 6.6051836013793945\n",
      "Epoch 400: Cost = 0.38702622056007385, W = -2.366278886795044, b = 7.188438892364502\n",
      "Epoch 500: Cost = 0.38493427634239197, W = -2.50982928276062, b = 7.620137691497803\n",
      "Epoch 600: Cost = 0.38370481133461, W = -2.62015962600708, b = 7.951305866241455\n",
      "Epoch 700: Cost = 0.3829473555088043, W = -2.706906795501709, b = 8.211335182189941\n",
      "Epoch 800: Cost = 0.3824652135372162, W = -2.776202440261841, b = 8.418843269348145\n",
      "Epoch 900: Cost = 0.3821509778499603, W = -2.832200765609741, b = 8.586403846740723\n",
      "Epoch 1000: Cost = 0.38194242119789124, W = -2.877850294113159, b = 8.722914695739746\n",
      "Epoch 1100: Cost = 0.38180220127105713, W = -2.9153144359588623, b = 8.834896087646484\n",
      "Epoch 1200: Cost = 0.3817068040370941, W = -2.946225643157959, b = 8.927254676818848\n",
      "Epoch 1300: Cost = 0.38164129853248596, W = -2.971832513809204, b = 9.003741264343262\n",
      "Epoch 1400: Cost = 0.38159605860710144, W = -2.9931187629699707, b = 9.067306518554688\n",
      "Epoch 1500: Cost = 0.3815648555755615, W = -3.010862350463867, b = 9.120281219482422\n",
      "Epoch 1600: Cost = 0.3815429210662842, W = -3.0256881713867188, b = 9.16453742980957\n",
      "Epoch 1700: Cost = 0.38152754306793213, W = -3.0380966663360596, b = 9.201571464538574\n",
      "Epoch 1800: Cost = 0.38151684403419495, W = -3.0484986305236816, b = 9.232614517211914\n",
      "Epoch 1900: Cost = 0.3815091550350189, W = -3.0572268962860107, b = 9.258659362792969\n",
      "Epoch 2000: Cost = 0.3815038204193115, W = -3.064560890197754, b = 9.280542373657227\n"
     ]
    }
   ],
   "source": [
    "bce = torch.nn.BCELoss()\n",
    "\n",
    "w = torch.randn(1, 1)\n",
    "b = torch.randn(1, 1)\n",
    "\n",
    "lr = 1.0\n",
    "\n",
    "for epoch in range(2001):\n",
    "    w.requires_grad_(True)\n",
    "    b.requires_grad_(True)\n",
    "\n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "\n",
    "    cost = bce(h, y_train)\n",
    "    cost.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Cost = {cost.item()}, W = {w.squeeze().tolist()}, b = {b.squeeze().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0109],\n",
      "        [0.9973]])\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.FloatTensor([[4.5],[1.1]])\n",
    "\n",
    "#test_result = torch.sigmoid(torch.mm(x_test, w) + b)\n",
    "test_result = torch.sigmoid(x_test @ w + b)\n",
    "\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2CklEQVR4nO3deVxVdeLG8ecCAmqA4IKYmGlZmaMmKjEtY0XSMpZZM45LmpX9MiqVapRKzTYy07HStDFLW0zTGW3RKMPUabQszclK29RkUkBzAsUE5fL74xsgCsqFy/3e5fN+vc7rHA7nwnPPONyns3yPo7S0tFQAAACWBNkOAAAAAhtlBAAAWEUZAQAAVlFGAACAVZQRAABgFWUEAABYRRkBAABWUUYAAIBVIbYD1ITT6dSuXbsUEREhh8NhOw4AAKiB0tJS7d+/X61atVJQUPXHP3yijOzatUvx8fG2YwAAgFrIzs5W69atq/2+T5SRiIgISebNREZGWk4DAABqoqCgQPHx8eWf49XxiTJSdmomMjKSMgIAgI852SUWXMAKAACsoowAAACrKCMAAMAqyggAALCKMgIAAKyijAAAAKsoIwAAwCrKCAAAsMonBj2rDyXOUq3fvk95+w+pRUS4ep4eo+AgnnvjbuxnzwnkfV2T9+7JbQC4xuUysmbNGk2ePFkbNmzQ7t27tWTJEvXt2/eEr1m1apXS0tL01VdfKT4+Xg8++KBuuummWkauu8wvd2vi219rd/6h8nVxUeGa0KejrugUZy2Xv2E/e04g7+uavHdPbgPAdY7S0tJSV17w7rvv6t///rcSEhLUr1+/k5aR7du3q1OnTrr99tt16623KisrS6NGjdKyZcuUkpJSo99ZUFCgqKgo5efn13k4+Mwvd2vEqxt17Jsu+++amYO78UfFDdjPnhPI+7om712Sx7bx1/0M1FZNP79dLiOVXuxwnLSMjBkzRsuWLdOXX35Zvu4vf/mLfvnlF2VmZtbo97irjJQ4S3XhpJWV/qvmaA5JLaPC9dGYSznsWgfsZ88J5H1dk/ceGxkmyaGcgrpt0zIqXKWlpcopKDrhNv64n4G6qOnnd71fM7Ju3TolJydXWpeSkqJRo0ZV+5qioiIVFVX8n76goMAtWdZv31fpD9fgjcvUuiCv/OvS3/4bJ+fHt3VqdEOzsuzhPsc+5Ofo9cduc/S2x37/RMsnm4KCqv766PmxyzWZgoOPnx87hYRUzKubGjSQQkK0/sf8aj8gzH6Wducf0vrt+5TUvmmN/rdD1Y79N30sf97XNXnv1ZUHV7c50e85eht/3M+AJ9R7GcnJyVFsbGyldbGxsSooKNCvv/6qhg0bHveajIwMTZw40e1Z8vZX/oNy3VcfKmHX1uM3/MTtvzqgJEn6LihYR4JCdDg4RMXBIToSFKzDwQ1UHByi4uAGOhwcotbvRklNI6WwMCk83ExhYVLDhmYKDzfzRo0qpsaNzfyUU8zUuLGZR0SYeVBg3SB27L/pum7nS7zxPXljJsAXeOXdNOnp6UpLSyv/uqCgQPHx8XX+uS0iwit9/fY5F2vjqWdXWucoLdVVv4tTqyYNpbIzWNXNa/K9o9cfPVW17mTbOJ2V58euL1sum479uqSk6nUlJZWXj/36yJHKy2Vfly1XoYGzRA2cJWp45AT/1ZlT/bdqLSJCiow0U5MmFVN0tJliYqSmTSum5s2lFi3M607yiGtvdOy/6bpu50u88T15YybAF9R7GWnZsqVyc3MrrcvNzVVkZGSVR0UkKSwsTGFhYW7P0vP0GMVFhSsn/5BKJc3tfk2l75ed9x025lKJ8741U1pqisnhw+XlpKSoWNdNW6V9+YUKKTmiBiVHFOo08wYlhxVackSx4Q5N7nO2go8clg4dMlNRkfTrr2b5118rTwcPSoWFFfPCQunAgYqppMTk2b/fTD/95Nr7CAszpSQ2VmrVSoqLM/NWraTWraU2baT4eFNavMix/6aPVfZvuufpMZ6OVu9q8t7LrgfJLajbNmXXjOQWFAXcfgY8od7LSFJSkpYvX15p3YoVK5SUlFTfv/o4wUEOTejTUSNe3SiHVOmPSln1mNCnIxegucLhqLhm5DfBku4YfLFGvLpRUtX7eebgbgp2150HpaWmwBQUVEz5+Wb65Rcz/e9/Zvr558rTnj2m2BQVSdnZZjqR6GhTTNq1k9q3r5jOPNOs9/BpokD+N12T9/7QNedKUp23mdCnY4228cf9DHiCy3fTHDhwQN9//70k6bzzztPUqVN1ySWXKCYmRm3atFF6erp++uknvfzyy5Iqbu1NTU3VzTffrJUrV+ruu++2dmuvxFgBnuIz+7mwUMrLM1NOjrR7t5l27TLTf/8r7dxpSs2JNGwonXWWdM450tlnS7/7ndSli3T66fV+Cshn9nU9YJwRwHvV2629q1at0iWXXHLc+qFDh2ru3Lm66aabtGPHDq1atarSa0aPHq2vv/5arVu31rhx41wa9MzdZURiFEVP8av9XFBgjpzs2CFt2yb98EPF9P335lRVVSIipM6dpfPOk3r2lBITzZEUNxcUv9rXLmIEVsA7eWScEU+pjzICuNWRI9L27dLWrdKWLdLXX0tffCF99ZVUXHz89tHRpphceKH0hz+Y5Xq4TgoAbKKMAN7g8GFTUP7zH2nDBumTT6SNG801KkcLD5eSkqRLLpGuuEJKSAi425QB+B/KCOCtioulzZuldeukNWuk1avN9SpHa97clJIrrzTz6Gg7WQGgDigjgK8oLTVHT1atkj74QFqxwtyeXKZBA+nyy6U//Um69lqKCQCfQRkBfFVxsbR2rbR8ubRsmbn+pExZMRk61BQTrjMB4MUoI4C/2LJFWrTITEc9cFIxMdLgwdLNN5tbiAHAy1BGAH+0ZYv02mvS3LmVR5nt2VMaPVq6/npz9AQAvEBNP7+5XB/wJeecIz36qPTjj9K775rrSBo0kNavlwYMMKPBTp588gHaAMCLUEYAXxQcbO6yeeMNM0LsxInm2TrZ2dJf/2qepzN2rBnyHgC8HGUE8HUtWkjjx5ujJS++KHXqZIa4nzTJDEU/fjxHSgB4NcoI4C/Cw6Vhw8zIr2+9JXXtam4RfuQRqW1b6fHHzQMFAcDLUEYAf+NwSH36mBFfFy+Wzj3XPMH4gQekjh2lpUvN2CYA4CUoI4C/Cgoyd9d88YX06qvSqaea5+dcd52UkmLuzAEAL0AZAfxdUJA0aJD0zTfm6EhoqBnltXNn8/Wxz8kBAA+jjACBonFjc1vw11+b0VuPHDHXkXTvbh7eBwCWUEaAQNO+vbluZPFi80C+L780g6ZNmGCGogcAD6OMAIHq+uulr76SbrhBKimRHn5YOv986fvvbScDEGAoI0Aga97cPPNm4UKpaVPp88+lhARpyRLbyQAEEMoIAOnPfzZ33VxwgVRQIPXrJ913n3T4sO1kAAIAZQSA0aqV9OGH0j33mK+fekq67DJp9267uQD4PcoIgAoNGpgS8o9/SJGR0r/+JSUmmotcAaCeUEYAHK9fP+mzz6SzzzYP37vgAmnlStupAPgpygiAqp15pvTvf0sXXWSuI7niCumVV2ynAuCHKCMAqhcTI73/vtS/v7mYdcgQ6bHHeLYNALeijAA4sfBwaf586a9/NV8/+KA0ZgyFBIDbUEYAnFxQkDRpkvT00+bryZNNOaGQAHADygiAmrv7bmnGDLP81FPSvfdSSADUGWUEgGvuuEOaOdMsT51qxiWhkACoA8oIANfdfrs0a5ZZ/tvfOEICoE4oIwBq5//+T3r+ebM8daqZAKAWKCMAau+228zFrJI5OrJggd08AHwSZQRA3dxzj7mwVTLjkHz4od08AHwOZQRA3Tgc5hTNDTeYgdH69pU2b7adCoAPoYwAqLvgYDNU/NFDx//3v7ZTAfARlBEA7hEeLr35ptSxo7RrlzlSUlRkOxUAH0AZAeA+0dHS22+b+SefVFxLAgAnQBkB4F7t2pln2Tgc0t//Lr3wgu1EALwcZQSA+11xhfTII2Y5NVVav95uHgBejTICoH6kp5s7a4qLpeuvl/LybCcC4KUoIwDqR1CQNG+e1KGDubPmL3+RSkpspwLghSgjAOpPZKS0dKnUuLEZDO2pp2wnAuCFKCMA6tc550hPP22Wx42TNm60mweA16GMAKh/N98sXXedGaF10CDp4EHbiQB4EcoIgPpXdptvXJy0dat03322EwHwIpQRAJ7RrJk0d65Zfu45adkyq3EAeA/KCADP6d1bGjnSLN98s5SbazcPAK9AGQHgWU88IXXqZMYdYbh4AKKMAPC08HDp5ZfNk37feEN65x3biQBYRhkB4HnnnSeNHm2W77hD2r/fbh4AVlFGANjx0EPS6adL2dlm/BEAAYsyAsCOxo2lWbPM8jPP8DA9IIBRRgDY07u3NHiwVFoqDR9uBkUDEHAoIwDsmjpVatpU+uILswwg4FBGANjVvHlFCXnoIenHH63GAeB5lBEA9t14o9Srl3TokDRmjO00ADyMMgLAPodD+tvfzHzhQumjj2wnAuBBlBEA3qFrV+nWW83yqFGS02kzDQAPoowA8B6PPipFRkobNkjz5tlOA8BDalVGZsyYobZt2yo8PFyJiYlaf5LxAaZNm6azzjpLDRs2VHx8vEaPHq1Dhw7VKjAAP9aiRcUAaPffz8isQIBwuYwsXLhQaWlpmjBhgjZu3KguXbooJSVFeXl5VW4/f/58jR07VhMmTNCWLVs0Z84cLVy4UPfff3+dwwPwQ3ffLZ1xhpSTIz3+uO00ADzA5TIydepUDR8+XMOGDVPHjh01a9YsNWrUSC+++GKV269du1YXXHCBBg4cqLZt26p3794aMGDASY+mAAhQoaHSlClmeepUads2u3kA1DuXykhxcbE2bNig5OTkih8QFKTk5GStW7euytf8/ve/14YNG8rLx7Zt27R8+XJdddVV1f6eoqIiFRQUVJoABJA+faTkZKm42JyuAeDXXCoje/fuVUlJiWJjYyutj42NVU5OTpWvGThwoB5++GFdeOGFatCggdq3b69evXqd8DRNRkaGoqKiyqf4+HhXYgLwdQ6H9NRTZnnhQmnTJqtxANSver+bZtWqVXr88cf13HPPaePGjfrnP/+pZcuW6ZFHHqn2Nenp6crPzy+fsrOz6zsmAG/TpYv0l7+YZZ7qC/i1EFc2btasmYKDg5Wbm1tpfW5urlq2bFnla8aNG6cbb7xRt/42fsDvfvc7FRYW6rbbbtMDDzygoKDj+1BYWJjCwsJciQbAH02cKC1aJL3zjrR2rfT739tOBKAeuHRkJDQ0VAkJCcrKyipf53Q6lZWVpaSkpCpfc/DgweMKR3BwsCSptLTU1bwAAkmHDtKwYWb5/vvN030B+B2XT9OkpaVp9uzZmjdvnrZs2aIRI0aosLBQw377gzFkyBClp6eXb9+nTx/NnDlTCxYs0Pbt27VixQqNGzdOffr0KS8lAFCt8ePNHTarV0sffGA7DYB64NJpGknq37+/9uzZo/HjxysnJ0ddu3ZVZmZm+UWtO3furHQk5MEHH5TD4dCDDz6on376Sc2bN1efPn302GOPue9dAPBf8fHSHXdI06aZoyPJyeYCVwB+w1HqA+dKCgoKFBUVpfz8fEVGRtqOA8DT8vKkdu2kwkLpn/+UrrvOdiIANVDTz2+eTQPA+7VoIY0ebZYffFAqKbGbB4BbUUYA+IZ77pGio6Wvv5b+8Q/baQC4EWUEgG9o0kQaOdIsP/YYd9YAfoQyAsB33HWXdMop0hdfmLFHAPgFyggA3xETY+6skTg6AvgRyggA35KWJoWHS598Iq1caTsNADegjADwLbGx0m+PlxDjFQF+gTICwPfcd58UEiJ9+KG0bp3tNADqiDICwPe0aSMNGWKWOToC+DzKCADfNHasFBQkLVsmbdpkOw2AOqCMAPBNZ54p9e9vljMy7GYBUCeUEQC+a+xYM1+8WNqxw2oUALVHGQHguzp3Nk/xdTqlZ5+1nQZALVFGAPi2tDQznz1bKiiwmwVArVBGAPi2lBTpnHOk/fulOXNspwFQC5QRAL4tKEgaPdosP/20dOSI3TwAXEYZAeD7Bg+WmjeXfvxRWrLEdhoALqKMAPB9DRtWPEBvyhQeoAf4GMoIAP8wYoQUFmYeoMcQ8YBPoYwA8A+xseZ0jSRNnWo3CwCXUEYA+I+yC1mXLJG2b7ebBUCNUUYA+I9zz5V69zaDoM2caTsNgBqijADwL6mpZj5njvTrr3azAKgRyggA/3L11VKbNtK+fdIbb9hOA6AGKCMA/EtwsHT77WZ5xgy7WQDUCGUEgP+59VYpNFT69FMzAfBqlBEA/qd5c+nPfzbLzz1nNwuAk6KMAPBPZReyLlgg/fyz3SwATogyAsA/JSZK550nHTokvfSS7TQAToAyAsA/ORwVR0dmzjRjjwDwSpQRAP5rwACpSRNp2zYpM9N2GgDVoIwA8F+NGknDhpllLmQFvBZlBIB/GzHCzN99V8rOtpsFQJUoIwD825lnSr16mWtGXnzRdhoAVaCMAPB/w4eb+Zw5UkmJ3SwAjkMZAeD/+vWToqPNaZr337edBsAxKCMA/F94uHTjjWb5hRfsZgFwHMoIgMBQdqrmrbek3Fy7WQBUQhkBEBg6dZLOP186ckSaO9d2GgBHoYwACBxlR0deeEEqLbWbBUA5ygiAwNG/vxQRIX3/vbRqle00AH5DGQEQOBo3lgYONMuzZ9vNAqAcZQRAYLn1VjP/xz+kn3+2mwWAJMoIgECTkCB17SoVF0uvvWY7DQBRRgAEGodDuuUWs8xdNYBXoIwACDwDBkgNGkiffy795z+20wABjzICIPA0bSpdc41Z5ugIYB1lBEBgGjbMzF991Vw/AsAaygiAwJSSIsXGSnv3Su++azsNENAoIwACU0hIxcPzOFUDWEUZARC4brrJzN95R8rLsxoFCGSUEQCB69xzpR49zMPz5s+3nQYIWJQRAIGt7OgIp2oAaygjAALbgAFSaKgZb+Tzz22nAQISZQRAYIuOlvr2NcscHQGsoIwAQNmpmtdeY8wRwIJalZEZM2aobdu2Cg8PV2JiotavX3/C7X/55RelpqYqLi5OYWFh6tChg5YvX16rwADgdpdfLrVsaZ7im5lpOw0QcFwuIwsXLlRaWpomTJigjRs3qkuXLkpJSVFeNbfFFRcX6/LLL9eOHTu0ePFiffPNN5o9e7ZOPfXUOocHALcICTHXjkjSK6/YzQIEIEdpaWmpKy9ITExUjx49NH36dEmS0+lUfHy87rrrLo0dO/a47WfNmqXJkydr69atatCgQa1CFhQUKCoqSvn5+YqMjKzVzwCAE/r8c6lbNyksTMrJkZo0sZ0I8Hk1/fx26chIcXGxNmzYoOTk5IofEBSk5ORkrVu3rsrXvPXWW0pKSlJqaqpiY2PVqVMnPf744yopKan29xQVFamgoKDSBAD1qmtXM+5IUZG0aJHtNEBAcamM7N27VyUlJYqNja20PjY2Vjk5OVW+Ztu2bVq8eLFKSkq0fPlyjRs3TlOmTNGjjz5a7e/JyMhQVFRU+RQfH+9KTABwncNRMTw8p2oAj6r3u2mcTqdatGihv//970pISFD//v31wAMPaNasWdW+Jj09Xfn5+eVTdnZ2fccEAGnQIFNK/vUvaccO22mAgOFSGWnWrJmCg4OVm5tbaX1ubq5atmxZ5Wvi4uLUoUMHBQcHl68755xzlJOTo+JqbqELCwtTZGRkpQkA6l3r1tIll5jlV1+1mwUIIC6VkdDQUCUkJCgrK6t8ndPpVFZWlpKSkqp8zQUXXKDvv/9eTqezfN23336ruLg4hYaG1jI2ANSTo0/VuHZ9P4Bacvk0TVpammbPnq158+Zpy5YtGjFihAoLCzVs2DBJ0pAhQ5Senl6+/YgRI7Rv3z6NHDlS3377rZYtW6bHH39cqamp7nsXAOAu118vNWwoffut9OmnttMAASHE1Rf0799fe/bs0fjx45WTk6OuXbsqMzOz/KLWnTt3KiioouPEx8frvffe0+jRo9W5c2edeuqpGjlypMaMGeO+dwEA7hIRYYaHf/11c3SkZ0/biQC/5/I4IzYwzggAj3r3Xemqq6RmzaRdu6RajpEEBLp6GWcEAALC5ZdLsbHS3r0MDw94AGUEAI519PDw3FUD1DvKCABUZdAgM3/rLYlRoIF6RRkBgKokJEgdOkiHDklLl9pOA/g1yggAVMXhqDg68tprdrMAfo4yAgDVGTjQzD/4wDzJF0C9oIwAQHXOOENKTJScTmnhQttpAL9FGQGAE+FUDVDvKCMAcCJ//rMUHGyGhv/uO9tpAL9EGQGAE4mNlZKTzfL8+XazAH6KMgIAJ3P0qRrvf4IG4HMoIwBwMn37mif5fved9NlnttMAfocyAgAnExEhXXutWeZCVsDtKCMAUBNlp2oWLJCOHLGbBfAzlBEAqImUFKlpUyk3V1q1ynYawK9QRgCgJho0kP70J7PMXTWAW1FGAKCmBgww83/8wzxAD4BbUEYAoKYuvFBq3VoqKJCWL7edBvAblBEAqKmgoIqjI5yqAdyGMgIArih7ku8770j5+XazAH6CMgIArujSRTrnHKmoSFq61HYawC9QRgDAFQ5HxdERTtUAbkEZAQBXlV038sEHZtwRAHVCGQEAV7VvL/XsKTmd0htv2E4D+DzKCADUBqdqALehjABAbfz5z+ZW348/lrZts50G8GmUEQCojbg46dJLzfLrr9vNAvg4yggA1NbRp2pKS+1mAXwYZQQAaqtfPyksTPr6a2nzZttpAJ9FGQGA2oqKkq6+2ixzIStQa5QRAKiLslM1r79ubvUF4DLKCADUxVVXSRER0s6d0tq1ttMAPokyAgB10bChuXZE4lQNUEuUEQCoq7JTNYsWSYcP280C+CDKCADU1aWXSi1aSHv3mufVAHAJZQQA6iokROrf3yxzqgZwGWUEANyh7FTNkiXSwYN2swA+hjICAO6QmCidfrpUWCi9/bbtNIBPoYwAgDs4HDzJF6glyggAuMuAAWb+7rvSvn12swA+hDICAO5y7rlS587m9t7Fi22nAXwGZQQA3GnQIDN/7TW7OQAfQhkBAHcaMMBcP7JmjRkiHsBJUUYAwJ3i46WLLzbLr79uNwvgIygjAOBunKoBXEIZAQB3u+EGKTRU2rzZTABOiDICAO4WHS1ddZVZ5ugIcFKUEQCoD2WnaubPl5xOu1kAL0cZAYD68Mc/SpGRUna29K9/2U4DeDXKCADUh/Bw6frrzTKnaoAToowAQH0pO1WzaJFUVGQ3C+DFKCMAUF969ZLi4qRffjHPqwFQJcoIANSX4OCKh+dxqgaoFmUEAOrT4MFm/vbb5ggJgONQRgCgPnXtKnXqZK4ZWbTIdhrAK1FGAKA+ORzSjTea5ZdftpsF8FK1KiMzZsxQ27ZtFR4ersTERK1fv75Gr1uwYIEcDof69u1bm18LAL5p4EBTSj76SNq+3XYawOu4XEYWLlyotLQ0TZgwQRs3blSXLl2UkpKivLy8E75ux44duvfee3XRRRfVOiwA+KTWraVLLzXLr75qNwvghVwuI1OnTtXw4cM1bNgwdezYUbNmzVKjRo304osvVvuakpISDRo0SBMnTlS7du3qFBgAfNKQIWb+yitSaandLICXcamMFBcXa8OGDUpOTq74AUFBSk5O1rp166p93cMPP6wWLVrolltuqdHvKSoqUkFBQaUJAHxav35So0bSd99Jn3xiOw3gVVwqI3v37lVJSYliY2MrrY+NjVVOTk6Vr/noo480Z84czZ49u8a/JyMjQ1FRUeVTfHy8KzEBwPuccop03XVm+ZVX7GYBvEy93k2zf/9+3XjjjZo9e7aaNWtW49elp6crPz+/fMrOzq7HlADgIWV31SxYIBUX280CeJEQVzZu1qyZgoODlZubW2l9bm6uWrZsedz2P/zwg3bs2KE+ffqUr3P+9ijtkJAQffPNN2rfvv1xrwsLC1NYWJgr0QDA+112mRkefvduMzz8tdfaTgR4BZeOjISGhiohIUFZWVnl65xOp7KyspSUlHTc9meffbY2b96sTZs2lU/XXHONLrnkEm3atInTLwACS0iIuc1X4lQNcBSXjoxIUlpamoYOHaru3burZ8+emjZtmgoLCzVs2DBJ0pAhQ3TqqacqIyND4eHh6tSpU6XXN2nSRJKOWw8AAeHGG6UpU8zw8Pv2STExthMB1rlcRvr37689e/Zo/PjxysnJUdeuXZWZmVl+UevOnTsVFMTArgBQpS5dpM6dpS++kBYulEaMsJ0IsM5RWur9N7wXFBQoKipK+fn5ioyMtB0HAOrmb3+T0tKknj25zRd+raaf3xzCAABPGzTIXD+yfr309de20wDWUUYAwNNatJCuvtosz51rNQrgDSgjAGDDTTeZ+SuvSEeOWI0C2EYZAQAbrr5aat5cysmRMjNtpwGsoowAgA0NGkiDB5tlTtUgwFFGAMCWslM1b70l7d1rNQpgE2UEAGzp3Fnq1k06fFh6/XXbaQBrKCMAYNNvo1frpZfs5gAsoowAgE0DBkihodLnn0v/+Y/tNIAVlBEAsKlpU+maa8wyF7IiQFFGAMC2o8ccKSqyGgWwgTICALalpEitW0s//ywtXWo7DeBxlBEAsC0kRLr5ZrP897/bzQJYQBkBAG9w882SwyGtXCn98IPtNIBHUUYAwBucdpo5XSNJL7xgNwvgYZQRAPAWt91m5i+9ZAZCAwIEZQQAvMUf/yjFxkq5udLbb9tOA3gMZQQAvEWDBhUjss6ebTcL4EGUEQDwJrfeaubvvSf9+KPdLICHUEYAwJu0by9ddplUWirNmWM7DeARlBEA8DbDh5v5iy9KR47YzQJ4AGUEALxN377mmTU//SQtX247DVDvKCMA4G3CwiouZH3uObtZAA+gjACANxoxwozI+t570nff2U4D1CvKCAB4o3btpCuvNMszZ9rNAtQzyggAeKvUVDN/6SWpsNBuFqAeUUYAwFtdcYU5QvLLL9L8+bbTAPWGMgIA3iooSLrjDrM8Y4YZewTwQ5QRAPBmw4ZJ4eHSf/4jrV1rOw1QLygjAODNYmKkgQPN8owZdrMA9YQyAgDeruxC1sWLzRN9AT9DGQEAb9etm3T++dLhwzzNF36JMgIAvuDOO8185kypuNhuFsDNKCMA4AtuuEFq2VLatUt64w3baQC3oowAgC8IC6s4OjJ1Krf5wq9QRgDAV9x+u9SwofT559KqVbbTAG5DGQEAX9G0acXTfKdMsZsFcCPKCAD4klGjzNN8ly2Ttm61nQZwC8oIAPiSM8+UrrnGLP/tb3azAG5CGQEAX3PPPWb+8svSnj12swBuQBkBAF9z4YVS9+7SoUNm3BHAx1FGAMDXOBwVR0dmzDClBPBhlBEA8EU33CC1aSPl5ZnTNYAPo4wAgC8KCZFGjzbLkyZJR47YzQPUAWUEAHzV8OFSs2bStm3SggW20wC1RhkBAF/VuLGUlmaWH39ccjrt5gFqiTICAL4sNVVq0kTaskVassR2GqBWKCMA4MsiI6W77zbLjz7KA/TgkygjAODr7r5bOuUUadMmafly22kAl1FGAMDXNW0q3XGHWX7kEY6OwOdQRgDAH6SlSeHh0iefSCtX2k4DuIQyAgD+IDZWuu02s/zII3azAC6ijACAv7jvPik0VFq9WsrKsp0GqDHKCAD4i9atpf/7P7N8//1cOwKfQRkBAH/ywANmMLT166U337SdBqgRyggA+JPYWGnUKLP8wANSSYnVOEBN1KqMzJgxQ23btlV4eLgSExO1fv36aredPXu2LrroIkVHRys6OlrJyckn3B4AUEf33itFR0tffy299prtNMBJuVxGFi5cqLS0NE2YMEEbN25Uly5dlJKSory8vCq3X7VqlQYMGKAPP/xQ69atU3x8vHr37q2ffvqpzuEBAFVo0kQaM8YsT5ggFRdbjQOcjKO01LUrnBITE9WjRw9Nnz5dkuR0OhUfH6+77rpLY8eOPenrS0pKFB0drenTp2vIkCE1+p0FBQWKiopSfn6+IiMjXYkLAIHp4EHpjDOk3bulZ5+V7rzTdiIEoJp+frt0ZKS4uFgbNmxQcnJyxQ8IClJycrLWrVtXo59x8OBBHT58WDExMdVuU1RUpIKCgkoTAMAFjRpJ48aZ5UcflQoL7eYBTsClMrJ3716VlJQoNja20vrY2Fjl5OTU6GeMGTNGrVq1qlRojpWRkaGoqKjyKT4+3pWYAABJuuUWqV07KTdXmjbNdhqgWh69m+aJJ57QggULtGTJEoWHh1e7XXp6uvLz88un7OxsD6YEAD8RGloxGmtGhrRrl908QDVcKiPNmjVTcHCwcnNzK63Pzc1Vy5YtT/jap556Sk888YTef/99de7c+YTbhoWFKTIystIEAKiFAQOkpCRzmqYG1/UBNrhURkJDQ5WQkKCso4YZdjqdysrKUlJSUrWve/LJJ/XII48oMzNT3bt3r31aAIBrHA7pmWfM8iuvSB9/bDcPUAWXT9OkpaVp9uzZmjdvnrZs2aIRI0aosLBQw4YNkyQNGTJE6enp5dtPmjRJ48aN04svvqi2bdsqJydHOTk5OnDggPveBQCget27S7/9jdbIkZLTaTcPcAyXy0j//v311FNPafz48eratas2bdqkzMzM8otad+7cqd27d5dvP3PmTBUXF+uGG25QXFxc+fTUU0+5710AAE7s8celU04xw8S/+qrtNEAlLo8zYgPjjACAGzz5pBkMLS5O+uYbKSLCdiL4uXoZZwQA4MNGjpTatzcDoWVk2E4DlKOMAECgCAuTpk41y1OmSN9+azcP8BvKCAAEkj59pCuuMM+rue02LmaFV6CMAEAgcTikmTPNcPGrV0tz5thOBFBGACDgtG0rPfaYWb7vPkZmhXWUEQAIRHfdJfXoIeXnm2XAIsoIAASi4GDphRekkBDpn/+UliyxnQgBjDICAIGqc2fpr381y6mp0i+/WI2DwEUZAYBANm6c1KGDGXvknntsp0GAoowAQCALD5dmzzZ32bz4ojllA3gYZQQAAt3FF1ecrhk+XPrpJ7t5EHAoIwAA6eGHpYQEad8+acgQBkODR1FGAABSaKj02mtmMLSVKyuGjQc8gDICADDOOkuaNs0s33+/9PnnVuMgcFBGAAAVbr1Vuu466fBhaeBAqbDQdiIEAMoIAKCCw2HurmnVStq6VbrlFqm01HYq+DnKCACgsqZNpYULzeisCxdKU6bYTgQ/RxkBABzvwgulp582y2PGSB98YDcP/BplBABQtREjpGHDzG2+/ftL27fbTgQ/RRkBAFTN4ZCee07q3t2MP9Kvn3TwoO1U8EOUEQBA9cLDzRDxzZtLmzZJN9/MgGhwO8oIAODE4uOlRYsqLmi97z7bieBnKCMAgJP7wx+kl14yy1OncocN3IoyAgComcGDpSefNMv33ivNn283D/wGZQQAUHP33iuNGmWWb7pJWrHCZhr4CcoIAKDmHA5ziqZ/fzNkfL9+0scf204FH0cZAQC4JihImjdPuvRS6cABqXdvae1a26ngwygjAADXhYVJb70l9eol7d8vpaRIH31kOxV8FGUEAFA7jRtLy5ZJl11mjpBccYW0erXtVPBBlBEAQO01aiS9/bZ0+eVSYaF05ZXSypW2U8HHUEYAAHXTsKH05pvmyMivv5pC8vrrtlPBh1BGAAB117ChtGSJdN11UnGxNHCglJEhlZbaTgYfQBkBALhHeLgZNn70aPP1/fdLw4ebW4CBE6CMAADcJzjYDBf/7LPmFuA5c6Srr5by820ngxejjAAA3O/OO6WlS80FritWSAkJ5qm/QBUoIwCA+tGnj7RmjdSmjfTDD9L550uzZ3MdCY5DGQEA1J+EBOnzz82pmqIi6bbbpKFDzW3AwG8oIwCA+hUTY0ZrfeIJc03JK69IPXpI69fbTgYvQRkBANS/oCBpzBgzIFpcnLRli5SUJI0dKx06ZDsdLKOMAAA85+KLpS+/lAYNkpxOadIkqVs3jpIEOMoIAMCzYmKkV181d9u0bFlxlOTuu6V9+2yngwWUEQCAHddeK331lTR4sDlK8uyzUocO0syZ0pEjttPBgygjAAB7YmLMBa0ffCB16iT9/LN0xx3m1A0P3AsYlBEAgH2XXWZuAZ4+XYqOljZvNusuvVT6179sp0M9o4wAALxDSIiUmip9950ZwbVBA+nDD81Fr5dfLq1dazsh6gllBADgXZo2NdePfP+9GSQtJMScxrngAqlXL+nNN6WSEtsp4UaUEQCAd2rTRnr+eXOk5NZbTSlZvVrq21c66yzpmWek/fttp4QbUEYAAN6tbVvzTJvt280gadHR5lk3I0dKrVqZorJ2Lc+88WGUEQCAb2jdWsrIkLKzze2/Z58tHTggzZljTuGcc44Zcj4723ZSuMhRWur9VbKgoEBRUVHKz89XZGSk7TgAAG9QWmrutHnpJemNN6SDByu+l5go3XCDdP310umn28sY4Gr6+U0ZAQD4vv37pUWLpHnzTEE5+qOtWzfz1OArr5R69jQP64NHUEYAAIFp925pyRJp8WJzwavTWfG9mBipd29zq/DFF0vt20sOh72sfo4yAgBAXp60bJmUmSm9/770yy+Vv9+qlfSHP5hicv75ZhTYkBArUf0RZQQAgKMdOSJ98okpJqtWmScFFxdX3qZhQ3Nap2dPKSFB6tLF3EbcoIGVyL6OMgIAwIn8+qv08cfSmjXSRx9Jn34q5ecfv11oqHTuuVLnzlLHjuYunrPPNhfGUlJOiDICwOuVOEu1fvs+5e0/pBYR4ep5eoyCg3z//L23vS9vy1MTVjI7nWaAtfXrzRGUTZukL76ofmC1kBCpXTtz3Un79ma5XTvptNPMgG3R0V5/PUp97+d6LSMzZszQ5MmTlZOToy5duujZZ59Vz549q91+0aJFGjdunHbs2KEzzzxTkyZN0lVXXVXj30cZAfxP5pe7NfHtr7U7/1D5uriocE3o01FXdIqzmKxuvO19eVuemvCqzKWl0o4dppR88YW0dWvFdPStxFVp3NiUktatzbUpcXFmatVKio2VWrQwU5MmVkqLJ/ZzvZWRhQsXasiQIZo1a5YSExM1bdo0LVq0SN98841atGhx3PZr167VxRdfrIyMDP3xj3/U/PnzNWnSJG3cuFGdOnVy65sB4Bsyv9ytEa9u1LF/fMr+HM8c3M1rPyhPxNvel7flqQmfyex0Sv/9rzmSsm2bGRF22zYz7dwp7dlT85/VoIHUrJl5Jk/ZFBNjpiZNKk+RkWaKiKiY1+JUkaf2c72VkcTERPXo0UPTp0+XJDmdTsXHx+uuu+7S2LFjj9u+f//+Kiws1DvvvFO+7vzzz1fXrl01a9Yst74ZAN6vxFmqCyetrPRfY0dzSGoZFa6Pxlzq9acSjuZt78vb8tSEL2au1q+/mrKyc6eZ794t7dpVMc/LM1NBQd1/V2iodMopZmrc2EyNGlWewsPNxbkNG8oZHq5Zn/yknw87VBQSqqLgEBWFhOqjtudpX6Mot+7nmn5+u3T/UnFxsTZs2KD09PTydUFBQUpOTta6deuqfM26deuUlpZWaV1KSoqWLl1a7e8pKipSUVFR+dcF7vgfC4BXWL99X7UfNpJUKml3/iGt375PSe2bei5YHXnb+/K2PDXhi5mr1bChdOaZZjqRoiJzFGXPHunnnytPv/wi/e9/Zl42FRSYa1gKCqRDv+2r4mJp3z4z1UCQpDuqWN9v8GTtaxRlZT+7VEb27t2rkpISxcbGVlofGxurrVu3VvmanJycKrfPycmp9vdkZGRo4sSJrkQD4CPy9lf/YVOb7byFt70vb8tTE76Yuc7Cwsw1Ja1bu/7a4mLzbJ7CQjMvmw4ePH769VczHTqk7dl79enWXQotOaywI4d/mxfrfw0rH7nw5H72ypFd0tPTKx1NKSgoUHx8vMVEANylRUS4W7fzFt72vrwtT034YmarQkMrri1xQc4PP+uvsz8+6Xae3M8uPbW3WbNmCg4OVm5ubqX1ubm5atmyZZWvadmypUvbS1JYWJgiIyMrTQD8Q8/TYxQXFa7qzkQ7ZK7o73m6a39gbfO29+VteWrCFzP7Im/czy6VkdDQUCUkJCgrK6t8ndPpVFZWlpKSkqp8TVJSUqXtJWnFihXVbg/AvwUHOTShT0dJOu6PYdnXE/p09P4LFI/hbe/L2/LUhC9m9kXeuJ9dKiOSlJaWptmzZ2vevHnasmWLRowYocLCQg0bNkySNGTIkEoXuI4cOVKZmZmaMmWKtm7dqoceekifffaZ7rzzTve9CwA+5YpOcZo5uJtaRlU+DNwyKtx7bt2sBW97X96WpyZ8MbMv8rb9XKtBz6ZPn14+6FnXrl31zDPPKDExUZLUq1cvtW3bVnPnzi3fftGiRXrwwQfLBz178sknGfQMgE+ODFoT3va+vC1PTfhiZl/k0yOwehplBAAA31PTz2+XT9MAAAC4E2UEAABYRRkBAABWUUYAAIBVlBEAAGAVZQQAAFhFGQEAAFZRRgAAgFWUEQAAYFWI7QA1UTZIbEFBgeUkAACgpso+t0822LtPlJH9+/dLkuLj4y0nAQAArtq/f7+ioqKq/b5PPJvG6XRq165dioiIkMPh3gf4xMfHKzs7m2fe1CP2s+ewrz2D/ewZ7GfPqM/9XFpaqv3796tVq1YKCqr+yhCfODISFBSk1q1b19vPj4yM5B+6B7CfPYd97RnsZ89gP3tGfe3nEx0RKcMFrAAAwCrKCAAAsCqgy0hYWJgmTJigsLAw21H8GvvZc9jXnsF+9gz2s2d4w372iQtYAQCA/wroIyMAAMA+yggAALCKMgIAAKyijAAAAKsCuozMmDFDbdu2VXh4uBITE7V+/XrbkfzOmjVr1KdPH7Vq1UoOh0NLly61HcnvZGRkqEePHoqIiFCLFi3Ut29fffPNN7Zj+aWZM2eqc+fO5YNDJSUl6d1337Udy6898cQTcjgcGjVqlO0ofuehhx6Sw+GoNJ199tlWsgRsGVm4cKHS0tI0YcIEbdy4UV26dFFKSory8vJsR/MrhYWF6tKli2bMmGE7it9avXq1UlNT9fHHH2vFihU6fPiwevfurcLCQtvR/E7r1q31xBNPaMOGDfrss8906aWX6tprr9VXX31lO5pf+vTTT/X888+rc+fOtqP4rXPPPVe7d+8unz766CMrOQL21t7ExET16NFD06dPl2SefxMfH6+77rpLY8eOtZzOPzkcDi1ZskR9+/a1HcWv7dmzRy1atNDq1at18cUX247j92JiYjR58mTdcssttqP4lQMHDqhbt2567rnn9Oijj6pr166aNm2a7Vh+5aGHHtLSpUu1adMm21EC88hIcXGxNmzYoOTk5PJ1QUFBSk5O1rp16ywmA+ouPz9fkvmQRP0pKSnRggULVFhYqKSkJNtx/E5qaqquvvrqSn+n4X7fffedWrVqpXbt2mnQoEHauXOnlRw+8aA8d9u7d69KSkoUGxtbaX1sbKy2bt1qKRVQd06nU6NGjdIFF1ygTp062Y7jlzZv3qykpCQdOnRIp5xyipYsWaKOHTvajuVXFixYoI0bN+rTTz+1HcWvJSYmau7cuTrrrLO0e/duTZw4URdddJG+/PJLRUREeDRLQJYRwF+lpqbqyy+/tHbeNxCcddZZ2rRpk/Lz87V48WINHTpUq1evppC4SXZ2tkaOHKkVK1YoPDzcdhy/duWVV5Yvd+7cWYmJiTrttNP0xhtvePy0Y0CWkWbNmik4OFi5ubmV1ufm5qply5aWUgF1c+edd+qdd97RmjVr1Lp1a9tx/FZoaKjOOOMMSVJCQoI+/fRTPf3003r++ectJ/MPGzZsUF5enrp161a+rqSkRGvWrNH06dNVVFSk4OBgiwn9V5MmTdShQwd9//33Hv/dAXnNSGhoqBISEpSVlVW+zul0Kisri3O/8DmlpaW68847tWTJEq1cuVKnn3667UgBxel0qqioyHYMv3HZZZdp8+bN2rRpU/nUvXt3DRo0SJs2baKI1KMDBw7ohx9+UFxcnMd/d0AeGZGktLQ0DR06VN27d1fPnj01bdo0FRYWatiwYbaj+ZUDBw5Uatnbt2/Xpk2bFBMTozZt2lhM5j9SU1M1f/58vfnmm4qIiFBOTo4kKSoqSg0bNrSczr+kp6fryiuvVJs2bbR//37Nnz9fq1at0nvvvWc7mt+IiIg47nqnxo0bq2nTplwH5Wb33nuv+vTpo9NOO027du3ShAkTFBwcrAEDBng8S8CWkf79+2vPnj0aP368cnJy1LVrV2VmZh53USvq5rPPPtMll1xS/nVaWpokaejQoZo7d66lVP5l5syZkqRevXpVWv/SSy/ppptu8nwgP5aXl6chQ4Zo9+7dioqKUufOnfXee+/p8ssvtx0NcNl///tfDRgwQD///LOaN2+uCy+8UB9//LGaN2/u8SwBO84IAADwDgF5zQgAAPAelBEAAGAVZQQAAFhFGQEAAFZRRgAAgFWUEQAAYBVlBAAAWEUZAQAAVlFGAACAVZQRAABgFWUEAABYRRkBAABW/T/mQwZbpgmhAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = torch.linspace(0, 5, 100).unsqueeze(1)\n",
    "Y = torch.sigmoid(X@w + b)\n",
    "\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(X, Y, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cost = 0.7806791663169861, W = 1.0136308670043945, b = 0.4170365333557129\n",
      "Epoch 100: Cost = 0.3822995126247406, W = -2.815603733062744, b = 8.524229049682617\n",
      "Epoch 200: Cost = 0.38150203227996826, W = -3.06817364692688, b = 9.291478157043457\n",
      "Epoch 300: Cost = 0.3814907371997833, W = -3.1019155979156494, b = 9.391989707946777\n",
      "Epoch 400: Cost = 0.3814908564090729, W = -3.103821277618408, b = 9.397658348083496\n",
      "Epoch 500: Cost = 0.3814908266067505, W = -3.103851556777954, b = 9.397749900817871\n",
      "Epoch 600: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 700: Cost = 0.3814907371997833, W = -3.1038520336151123, b = 9.397749900817871\n",
      "Epoch 800: Cost = 0.3814908266067505, W = -3.103851556777954, b = 9.397749900817871\n",
      "Epoch 900: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1000: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1100: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1200: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1300: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1400: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1500: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1600: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1700: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1800: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 1900: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n",
      "Epoch 2000: Cost = 0.3814907371997833, W = -3.103851795196533, b = 9.397749900817871\n"
     ]
    }
   ],
   "source": [
    "bce = torch.nn.BCELoss()\n",
    "\n",
    "w = torch.randn(1, 1, requires_grad=True)\n",
    "b = torch.randn(1, 1, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([w, b], lr=1.0)\n",
    "\n",
    "for epoch in range(2001):\n",
    "\n",
    "    h = torch.sigmoid(x_train @ w + b)\n",
    "    cost = bce(h, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Cost = {cost.item()}, W = {w.squeeze().tolist()}, b = {b.squeeze().item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn에서LogisticRegression사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.10428163]] [9.39919938]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train = [[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]]\n",
    "y_train = [1,1,1,0,0,0,0,1,0,1,1,1] \n",
    "\n",
    "model = LogisticRegression(penalty=None)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "print(model.coef_, model.intercept_)\n",
    "\n",
    "x_test = [[4.5], [1.1]]\n",
    "test_result = model.predict(x_test)\n",
    "print(test_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L06.1 Softmax Regression Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train = torch.FloatTensor([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5],[1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
    "y_train = torch.FloatTensor([ [0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0], [1,0,0], [1,0,0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4742, -0.3879,  0.3331],\n",
      "        [-1.7264, -0.9668,  0.6214],\n",
      "        [-0.9171,  0.1999, -0.8467],\n",
      "        [-1.5838,  1.7563,  0.0731]], requires_grad=True)\n",
      "tensor([[-0.8060,  0.7452, -0.2738]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(4, 3, requires_grad=True)\n",
    "b = torch.randn(1, 3, requires_grad=True)\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "optimizer = torch.optim.Adam([W, b], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 10.677729\n",
      "epoch: 100, cost: 0.361586\n",
      "epoch: 200, cost: 0.263240\n",
      "epoch: 300, cost: 0.197887\n",
      "epoch: 400, cost: 0.152961\n",
      "epoch: 500, cost: 0.121566\n",
      "epoch: 600, cost: 0.098918\n",
      "epoch: 700, cost: 0.082033\n",
      "epoch: 800, cost: 0.069085\n",
      "epoch: 900, cost: 0.058923\n",
      "epoch: 1000, cost: 0.050792\n",
      "epoch: 1100, cost: 0.044184\n",
      "epoch: 1200, cost: 0.038739\n",
      "epoch: 1300, cost: 0.034200\n",
      "epoch: 1400, cost: 0.030378\n",
      "epoch: 1500, cost: 0.027129\n",
      "epoch: 1600, cost: 0.024346\n",
      "epoch: 1700, cost: 0.021943\n",
      "epoch: 1800, cost: 0.019856\n",
      "epoch: 1900, cost: 0.018031\n",
      "epoch: 2000, cost: 0.016427\n",
      "epoch: 2100, cost: 0.015010\n",
      "epoch: 2200, cost: 0.013752\n",
      "epoch: 2300, cost: 0.012631\n",
      "epoch: 2400, cost: 0.011627\n",
      "epoch: 2500, cost: 0.010726\n",
      "epoch: 2600, cost: 0.009913\n",
      "epoch: 2700, cost: 0.009179\n",
      "epoch: 2800, cost: 0.008513\n",
      "epoch: 2900, cost: 0.007907\n",
      "epoch: 3000, cost: 0.007355\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3001):\n",
    "    h = torch.softmax(torch.mm(x_train, W)+b, dim=1)\n",
    "    cost = -torch.mean(torch.sum(y_train * torch.log(h), dim=1))  # dim은 가로를 1로 할 것인지 세로를 1로 할 것인지 결정함\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 2.7023e-17, 1.7591e-35],\n",
      "        [6.2918e-03, 8.5004e-01, 1.4367e-01],\n",
      "        [4.4188e-31, 3.7758e-11, 1.0000e+00]])\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "W.requires_grad_(False)\n",
    "b.requires_grad_(False)\n",
    "\n",
    "x_test = torch.FloatTensor([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
    "test_all = torch.softmax(torch.mm(x_test, W)+b, dim=1)\n",
    "print(test_all)\n",
    "print(torch.argmax(test_all, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 3, 2, 6, 4], [7, 2, 3, 9, 8]], dtype=torch.float)\n",
    "torch.argmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 10.404158\n",
      "epoch: 100, cost: 0.372091\n",
      "epoch: 200, cost: 0.262537\n",
      "epoch: 300, cost: 0.190108\n",
      "epoch: 400, cost: 0.143506\n",
      "epoch: 500, cost: 0.112316\n",
      "epoch: 600, cost: 0.090360\n",
      "epoch: 700, cost: 0.074244\n",
      "epoch: 800, cost: 0.062029\n",
      "epoch: 900, cost: 0.052537\n",
      "epoch: 1000, cost: 0.045011\n",
      "epoch: 1100, cost: 0.038946\n",
      "epoch: 1200, cost: 0.033986\n",
      "epoch: 1300, cost: 0.029881\n",
      "epoch: 1400, cost: 0.026445\n",
      "epoch: 1500, cost: 0.023543\n",
      "epoch: 1600, cost: 0.021068\n",
      "epoch: 1700, cost: 0.018942\n",
      "epoch: 1800, cost: 0.017103\n",
      "epoch: 1900, cost: 0.015501\n",
      "epoch: 2000, cost: 0.014098\n",
      "epoch: 2100, cost: 0.012862\n",
      "epoch: 2200, cost: 0.011768\n",
      "epoch: 2300, cost: 0.010795\n",
      "epoch: 2400, cost: 0.009927\n",
      "epoch: 2500, cost: 0.009148\n",
      "epoch: 2600, cost: 0.008448\n",
      "epoch: 2700, cost: 0.007815\n",
      "epoch: 2800, cost: 0.007243\n",
      "epoch: 2900, cost: 0.006723\n",
      "epoch: 3000, cost: 0.006250\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "x_train = torch.FloatTensor([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
    "y_train = torch.LongTensor([2,2,2,1,1,1,0,0])\n",
    "\n",
    "W = torch.randn(4, 3 ,requires_grad=True)  \n",
    "b = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([W, b], lr=0.1)\n",
    "\n",
    "for epoch in range(3001):\n",
    "    h = torch.mm(x_train, W) + b\n",
    "    cost = F.cross_entropy(h, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, cost: 2.425158\n",
      "epoch: 100, cost: 0.319835\n",
      "epoch: 200, cost: 0.194931\n",
      "epoch: 300, cost: 0.129679\n",
      "epoch: 400, cost: 0.092538\n",
      "epoch: 500, cost: 0.069399\n",
      "epoch: 600, cost: 0.053990\n",
      "epoch: 700, cost: 0.043206\n",
      "epoch: 800, cost: 0.035360\n",
      "epoch: 900, cost: 0.029470\n",
      "epoch: 1000, cost: 0.024932\n",
      "epoch: 1100, cost: 0.021360\n",
      "epoch: 1200, cost: 0.018496\n",
      "epoch: 1300, cost: 0.016162\n",
      "epoch: 1400, cost: 0.014234\n",
      "epoch: 1500, cost: 0.012623\n",
      "epoch: 1600, cost: 0.011261\n",
      "epoch: 1700, cost: 0.010100\n",
      "epoch: 1800, cost: 0.009101\n",
      "epoch: 1900, cost: 0.008235\n",
      "epoch: 2000, cost: 0.007480\n",
      "epoch: 2100, cost: 0.006817\n",
      "epoch: 2200, cost: 0.006232\n",
      "epoch: 2300, cost: 0.005713\n",
      "epoch: 2400, cost: 0.005251\n",
      "epoch: 2500, cost: 0.004837\n",
      "epoch: 2600, cost: 0.004465\n",
      "epoch: 2700, cost: 0.004130\n",
      "epoch: 2800, cost: 0.003827\n",
      "epoch: 2900, cost: 0.003552\n",
      "epoch: 3000, cost: 0.003302\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "x_train = torch.FloatTensor([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
    "y_train = torch.LongTensor([2,2,2,1,1,1,0,0])\n",
    "\n",
    "model = nn.Linear(4, 3) # 입력: 4차원, 클래스 개수: 3개\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(3001):\n",
    "    h = model(x_train)\n",
    "    cost = F.cross_entropy(h, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-18.7836,  -0.9238,  13.0564,  -3.3200],\n",
      "        [  3.7991,  -0.0686,  -0.8083,   1.6024],\n",
      "        [  5.3276,   0.2555,  -6.5349,   0.1571]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-27.2885,  -6.1013,  17.5326], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for a in model.parameters():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train = np.array([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [ 1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
    " # y에 0, 1, 2 등 둘 이상의 class가 존재 => softmax regression\n",
    "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0 ])\n",
    "\n",
    "logistic = LogisticRegression() # 모델 생성\n",
    "logistic.fit(x_train, y_train) # 학습\n",
    "\n",
    "pred = logistic.predict([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
